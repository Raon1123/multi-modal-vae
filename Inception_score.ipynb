{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/sundyCoder/IS_MS_SS\n",
    "import os, sys\n",
    "import imageio\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import glob as glob\n",
    "from numpy import clip\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '.Gen_dataset/VAE/MNIST/'\n",
    "\n",
    "data = torch.load(os.path.join(data_dir,'generated_data.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "data_list = [x.detach().numpy() for x in data['x']]\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds2score(preds, splits=10):\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
    "        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
    "        kl = np.mean(np.sum(kl, 1))\n",
    "        scores.append(np.exp(kl))\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "\n",
    "def get_inception_score_mnist(images):\n",
    "    num_splits=10\n",
    "    batch_size = 100\n",
    "    model_dir = './models/checkpoints/mnist_model_10.ckpt'\n",
    "    splits = num_splits\n",
    "    inps = []\n",
    "    input_transform = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    for img in images:\n",
    "        img = img.astype(np.float32)\n",
    "        inps.append(np.expand_dims(img, 0))\n",
    "    preds = []\n",
    "    #pred_acc = []\n",
    "    n_batches = int(math.ceil(float(len(inps)) / float(batch_size)))\n",
    "    n_preds = 0\n",
    "\n",
    "    net = ResNet18().cuda()\n",
    "    net.load_state_dict(torch.load(model_dir))\n",
    "    print(\"load model successfully\")\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "        inp = inps[(i * batch_size):min((i + 1) * batch_size, len(inps))]\n",
    "        inp = np.concatenate(inp, 0)\n",
    "        inp = np.expand_dims(inp, axis=1)\n",
    "        inp = torch.from_numpy(inp).cuda()\n",
    "        outputs = net(inp)\n",
    "        pred = outputs.data.tolist()\n",
    "        pred = softmax(pred)\n",
    "        preds.append(pred)\n",
    "        n_preds += outputs.shape[0]\n",
    "    preds = np.concatenate(preds, 0)\n",
    "    preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)\n",
    "    mean_, std_ = preds2score(preds, splits)\n",
    "    return mean_, std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model successfully\n",
      "....................................................................................................\n",
      "Inception mean:  1.0063228150435726\n",
      "Inception std:  0.0037650017228050324\n"
     ]
    }
   ],
   "source": [
    "mean, std = get_inception_score_mnist(data_list)\n",
    "print('\\nInception mean: ', mean)\n",
    "print('Inception std: ', std)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception score for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Gen_datset/VAE/CIFAR-10/'\n",
    "\n",
    "data = torch.load(os.path.join(data_dir,'generated_data.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "cifar_data_list = [x.detach().numpy() for x in data['x']]\n",
    "print(len(cifar_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/tmp/imagenet'\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "softmax = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inception_score_cifar(images):\n",
    "  num_splits = 2\n",
    "  tensor_layout = 'NHWC'\n",
    "  splits = num_splits\n",
    "  layout = tensor_layout\n",
    "\n",
    "  assert(type(images) == list)\n",
    "  assert(type(images[0]) == np.ndarray)\n",
    "  assert(len(images[0].shape) == 3)\n",
    "  print(images[0].min(), images[0].max(), images[0].dtype)\n",
    "  # assert(np.max(images[0]) > 10)\n",
    "  # assert(np.min(images[0]) >= 0.0)\n",
    "  inps = []\n",
    "  for img in images:\n",
    "    img = img.astype(np.float32)\n",
    "    inps.append(np.expand_dims(img, 0))\n",
    "  bs = 100\n",
    "  with tf.Session() as sess:\n",
    "    preds = []\n",
    "    n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n",
    "    n_preds = 0\n",
    "    for i in range(n_batches):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "        inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n",
    "        inp = np.concatenate(inp, 0)\n",
    "        if layout == 'NCHW':\n",
    "          inp = inp.transpose(0, 2, 3, 1)\n",
    "        pred = sess.run(softmax, {'ExpandDims:0': inp})\n",
    "        preds.append(pred)\n",
    "        n_preds += pred.shape[0]\n",
    "        print('Ran %d / %d images' % (n_preds, len(images)))    \n",
    "    preds = np.concatenate(preds, 0)\n",
    "    #preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "      part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
    "      kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
    "      kl = np.mean(np.sum(kl, 1))\n",
    "      scores.append(np.exp(kl))\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# This function is called automatically.\n",
    "def _init_inception():\n",
    "  global softmax\n",
    "  if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(MODEL_DIR, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
    "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)\n",
    "  with tf.gfile.FastGFile(os.path.join(\n",
    "      MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "  # Works with an arbitrary minibatch size.\n",
    "  with tf.Session() as sess:\n",
    "    pool3 = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "    ops = pool3.graph.get_operations()\n",
    "    for op_idx, op in enumerate(ops):\n",
    "        for o in op.outputs:\n",
    "            shape = o.shape\n",
    "            shape = list(shape)\n",
    "            new_shape = []\n",
    "            for j, s in enumerate(shape):\n",
    "                if s == 1 and j == 0:\n",
    "                    new_shape.append(None)\n",
    "                else:\n",
    "                    new_shape.append(s)\n",
    "            o.__dict__['_shape_val'] = tf.TensorShape(new_shape)\n",
    "            #o._shape = tf.TensorShape(new_shape)\n",
    "    w = sess.graph.get_operation_by_name(\"softmax/logits/MatMul\").inputs[1]\n",
    "    logits = tf.matmul(tf.squeeze(pool3,[1,2]), w)\n",
    "    #sslogits = tf.matmul(tf.squeeze(pool3), w)\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "if softmax is None:\n",
    "  _init_inception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41666007 0.76279896 float32\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 12:05:37.810358: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 100 / 10000 images\n",
      ".Ran 200 / 10000 images\n",
      ".Ran 300 / 10000 images\n",
      ".Ran 400 / 10000 images\n",
      ".Ran 500 / 10000 images\n",
      ".Ran 600 / 10000 images\n",
      ".Ran 700 / 10000 images\n",
      ".Ran 800 / 10000 images\n",
      ".Ran 900 / 10000 images\n",
      ".Ran 1000 / 10000 images\n",
      ".Ran 1100 / 10000 images\n",
      ".Ran 1200 / 10000 images\n",
      ".Ran 1300 / 10000 images\n",
      ".Ran 1400 / 10000 images\n",
      ".Ran 1500 / 10000 images\n",
      ".Ran 1600 / 10000 images\n",
      ".Ran 1700 / 10000 images\n",
      ".Ran 1800 / 10000 images\n",
      ".Ran 1900 / 10000 images\n",
      ".Ran 2000 / 10000 images\n",
      ".Ran 2100 / 10000 images\n",
      ".Ran 2200 / 10000 images\n",
      ".Ran 2300 / 10000 images\n",
      ".Ran 2400 / 10000 images\n",
      ".Ran 2500 / 10000 images\n",
      ".Ran 2600 / 10000 images\n",
      ".Ran 2700 / 10000 images\n",
      ".Ran 2800 / 10000 images\n",
      ".Ran 2900 / 10000 images\n",
      ".Ran 3000 / 10000 images\n",
      ".Ran 3100 / 10000 images\n",
      ".Ran 3200 / 10000 images\n",
      ".Ran 3300 / 10000 images\n",
      ".Ran 3400 / 10000 images\n",
      ".Ran 3500 / 10000 images\n",
      ".Ran 3600 / 10000 images\n",
      ".Ran 3700 / 10000 images\n",
      ".Ran 3800 / 10000 images\n",
      ".Ran 3900 / 10000 images\n",
      ".Ran 4000 / 10000 images\n",
      ".Ran 4100 / 10000 images\n",
      ".Ran 4200 / 10000 images\n",
      ".Ran 4300 / 10000 images\n",
      ".Ran 4400 / 10000 images\n",
      ".Ran 4500 / 10000 images\n",
      ".Ran 4600 / 10000 images\n",
      ".Ran 4700 / 10000 images\n",
      ".Ran 4800 / 10000 images\n",
      ".Ran 4900 / 10000 images\n",
      ".Ran 5000 / 10000 images\n",
      ".Ran 5100 / 10000 images\n",
      ".Ran 5200 / 10000 images\n",
      ".Ran 5300 / 10000 images\n",
      ".Ran 5400 / 10000 images\n",
      ".Ran 5500 / 10000 images\n",
      ".Ran 5600 / 10000 images\n",
      ".Ran 5700 / 10000 images\n",
      ".Ran 5800 / 10000 images\n",
      ".Ran 5900 / 10000 images\n",
      ".Ran 6000 / 10000 images\n",
      ".Ran 6100 / 10000 images\n",
      ".Ran 6200 / 10000 images\n",
      ".Ran 6300 / 10000 images\n",
      ".Ran 6400 / 10000 images\n",
      ".Ran 6500 / 10000 images\n",
      ".Ran 6600 / 10000 images\n",
      ".Ran 6700 / 10000 images\n",
      ".Ran 6800 / 10000 images\n",
      ".Ran 6900 / 10000 images\n",
      ".Ran 7000 / 10000 images\n",
      ".Ran 7100 / 10000 images\n",
      ".Ran 7200 / 10000 images\n",
      ".Ran 7300 / 10000 images\n",
      ".Ran 7400 / 10000 images\n",
      ".Ran 7500 / 10000 images\n",
      ".Ran 7600 / 10000 images\n",
      ".Ran 7700 / 10000 images\n",
      ".Ran 7800 / 10000 images\n",
      ".Ran 7900 / 10000 images\n",
      ".Ran 8000 / 10000 images\n",
      ".Ran 8100 / 10000 images\n",
      ".Ran 8200 / 10000 images\n",
      ".Ran 8300 / 10000 images\n",
      ".Ran 8400 / 10000 images\n",
      ".Ran 8500 / 10000 images\n",
      ".Ran 8600 / 10000 images\n",
      ".Ran 8700 / 10000 images\n",
      ".Ran 8800 / 10000 images\n",
      ".Ran 8900 / 10000 images\n",
      ".Ran 9000 / 10000 images\n",
      ".Ran 9100 / 10000 images\n",
      ".Ran 9200 / 10000 images\n",
      ".Ran 9300 / 10000 images\n",
      ".Ran 9400 / 10000 images\n",
      ".Ran 9500 / 10000 images\n",
      ".Ran 9600 / 10000 images\n",
      ".Ran 9700 / 10000 images\n",
      ".Ran 9800 / 10000 images\n",
      ".Ran 9900 / 10000 images\n",
      ".Ran 10000 / 10000 images\n",
      "Inception mean:  1.0000107\n",
      "Inception std:  1.7881393e-06\n"
     ]
    }
   ],
   "source": [
    "mean, std = get_inception_score_cifar(cifar_data_list)\n",
    "print('Inception mean: ', mean)\n",
    "print('Inception std: ', std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
